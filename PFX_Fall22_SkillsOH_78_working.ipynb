{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997b54bd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "notebook_header"
    ]
   },
   "source": [
    "# `Final Exam`, `Fall 2022`: `Time Series Analysis of US Inflation`\n",
    "_Version 1.0.1_\n",
    "\n",
    "Change history:   \n",
    "1.0.1 - bugfix ex2 test code.  \n",
    "1.0 - initial release  \n",
    "\n",
    "*All of the header information is important. Please read it..*\n",
    "\n",
    "**Topics, number of exercises:** This problem builds on your knowledge of Pandas, Numpy, basic Python data structures, and implementing mathematical functions. It has **9** exercises, numbered 0 to **8**. There are **18** available points. However, to earn 100% the threshold is **13** points. (Therefore, once you hit **13** points, you can stop. There is no extra credit for exceeding this threshold.)\n",
    "\n",
    "**Exercise ordering:** Each exercise builds logically on previous exercises, but you may solve them in any order. That is, if you can't solve an exercise, you can still move on and try the next one. Use this to your advantage, as the exercises are **not** necessarily ordered in terms of difficulty. Higher point values generally indicate more difficult exercises. \n",
    "\n",
    "**Demo cells:** Code cells starting with the comment `### define demo inputs` load results from prior exercises applied to the entire data set and use those to build demo inputs. These must be run for subsequent demos to work properly, but they do not affect the test cells. The data loaded in these cells may be rather large (at least in terms of human readability). You are free to print or otherwise use Python to explore them, but we did not print them in the starter code.\n",
    "\n",
    "**Debugging your code:** Right before each exercise test cell, there is a block of text explaining the variables available to you for debugging. You may use these to test your code and can print/display them as needed (careful when printing large objects, you may want to print the head or chunks of rows at a time).\n",
    "\n",
    "**Exercise point breakdown:**\n",
    "\n",
    "- Exercise 0: **1** point(s)\n",
    "- Exercise 1: **1** point(s)\n",
    "- Exercise 2: **2** point(s)\n",
    "- Exercise 3: **2** point(s)\n",
    "- Exercise 4: **2** point(s)\n",
    "- Exercise 5: **2** point(s)\n",
    "- Exercise 6: **2** point(s)\n",
    "- Exercise 7: **3** point(s)\n",
    "- Exercise 8: **3** point(s)\n",
    "\n",
    "**Final reminders:** \n",
    "\n",
    "- Submit after **every exercise**\n",
    "- Review the generated grade report after you submit to see what errors were returned\n",
    "- Stay calm, skip problems as needed, and take short breaks at your leisure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f0ecc3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "topic_intro"
    ]
   },
   "source": [
    "## Background Inflation\n",
    "\n",
    "Inflation is an increase in overall prices in an economy over time. Deflation is \"negative inflation\", a decrease in prices over time. A common way to measure inflation is to first calculate the CPI (price of a representative basket of goods), then compute the difference in CPI over a time interval. In other words if the CPI is 100 at one point in time, and the CPI is 105 one year later then we would say that the inflation rate over that year was 5%.\n",
    "\n",
    "## Data\n",
    "\n",
    "We have obtained the US CPI for each month going back to the early 20th century from The Organisation for Economic Co-operation and Development. \n",
    "\n",
    "## Analysis goals\n",
    "- Use the CPI data to calculate the inflation rate at any point in history over an arbitrary number of months.\n",
    "- Attempt to predict the inflation rate in future months based on the inflation rate in previous months using exponential smoothing models.\n",
    "    - Evaluate how \"good\" the predictions are.\n",
    "    - Tune the models to pick the best parameters.\n",
    "    - Make inferences based on the selected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf8340c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "global_imports"
    ]
   },
   "outputs": [],
   "source": [
    "### Global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a9824",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 0 - (**1** Points): \n",
    "To start things off we will load the CPI data into the notebook environment. You do not need to modify the cell below, just execute the test and collect your free point!\n",
    "\n",
    "This cell will also display the first few rows and last few rows of the CPI data we just loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77aa46c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "cpi_all_df = pd.read_csv('cpi_urban_all.csv')\n",
    "display(cpi_all_df.head())\n",
    "display(cpi_all_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61de83f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 0. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa5310",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex0",
     "locked": true,
     "points": "1",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex0\n",
    "assert 'cpi_all_df' in globals()\n",
    "assert isinstance(cpi_all_df, pd.DataFrame)\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191284b7",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## Grid search\n",
    "\n",
    "Calculus won't work for finding the optimal parameters for either flavor of exponential smoothing implemented above. A \"brute-force\" alternative is to generate a list of suitable candidates for each parameter and test our functions on all possible combinations. This is called a grid search. It's not flashy, but for a lot of modeling techniques it's one of the only suitable choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8978d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 7 - (**3** Points): \n",
    "Define the function `build_grid(params)`. The input `params` will be a dictionary mapping strings to arrays (or array-like data structures such as `list`s). Consider each string a parameter name and each value in the corresponding array to be a candidate value for that parameter.\n",
    "\n",
    "Your function should return a list of dictionaries which satisfies the following:  \n",
    "- Each dictionary maps each parameter name to exactly one candidate value for that parameter.\n",
    "- Exactly one dictionary exists for each combination of parameters. \n",
    "- The list is sorted by the values associated with each key. The sort priority for each key should be based on their lexographical order.\n",
    "\n",
    "For example, `build_params({'b': [1, 2], 'z': [3, 5, 6], 'a': [100, 10]})` should return:  \n",
    "```\n",
    "[{'b': 1, 'z': 3, 'a': 10},\n",
    " {'b': 1, 'z': 5, 'a': 10},\n",
    " {'b': 1, 'z': 6, 'a': 10},\n",
    " {'b': 2, 'z': 3, 'a': 10},\n",
    " {'b': 2, 'z': 5, 'a': 10},\n",
    " {'b': 2, 'z': 6, 'a': 10},\n",
    " {'b': 1, 'z': 3, 'a': 100},\n",
    " {'b': 1, 'z': 5, 'a': 100},\n",
    " {'b': 1, 'z': 6, 'a': 100},\n",
    " {'b': 2, 'z': 3, 'a': 100},\n",
    " {'b': 2, 'z': 5, 'a': 100},\n",
    " {'b': 2, 'z': 6, 'a': 100}]\n",
    "```\n",
    "\n",
    "Notice the following:  \n",
    "- There are 3 parameters. The length of the lists assigned to the parameters are 2, 3, and 2.  \n",
    "    - Thus there are 12 (`2*3*2`)possible combinations.  \n",
    "- Each possible combination is represented exactly once in the list. \n",
    "- The list is sorted first by the `'a'` value, then by the `'b'` value, and finally by the `'z'` value.\n",
    "\n",
    "Keep in mind that the function needs to work for an **arbitrary** dictionary (the number of keys, the keys themselves, and the values can be **anything** which meets the which has the structure given earlier in the prompt).\n",
    "\n",
    "**Note**: You may find the functions `itertools.product` or `numpy.meshgrid` helpful in solving this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eafa6f1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [],
   "source": [
    "### Define demo inputs\n",
    "\n",
    "demo_params_ex7 = {'b': [1, 2], 'z': [3, 5, 6], 'a': [100, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733888e",
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "### Exercise 7 solution\n",
    "def build_grid(params):\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "### demo function call\n",
    "build_grid(demo_params_ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c474dea",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 7. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5bc21",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex7",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex7\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_7', \n",
    "    'func': build_grid, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'params':{\n",
    "            'dtype':'dict', # data type of param.\n",
    "            'check_modified':False,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': True, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'z0BNF11iKYQicR63590bVXZGa19YGvJcmzrbP6R7oAY=', path='')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cfc2b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "## A metric to compare models\n",
    "In order to implement a grid search we need some metric of evaluating how well each model fits the data. We have provided `mse` to calculate the mean squared error for the predictions coming from a model. It takes two 1-D array arguments, `obs` (observed values) and `preds` (predicted values). It returns the mean of the squared difference between observations and predictions. A lower output from `mse` indicates that the model is a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda51c47",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def mse(obs, preds):\n",
    "    r = obs-preds\n",
    "    return np.power(r,2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1a5cc0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "exercise_text"
    ]
   },
   "source": [
    "## Exercise 8 - (**3** Points): \n",
    "Now that we have built our parameter grid, it's time to test it.\n",
    "\n",
    "Define the function `grid_search(func, ts, grid, n_back)`. The inputs are as follows.  \n",
    "- `func`: an _arbitrary_ function similar to the ones which we defined in exercises 5 and 6. It takes a 1-D time-series array and some additional parameters as inputs. It returns predictions for the time series based on some logic of which we are unaware.\n",
    "    - You can consider `func(...)[i]` to be the prediction that corresponds with `ts[i]`. \n",
    "    - `func(...)[-1]` is the prediction for the next value of `ts` which has not been observed yet. \n",
    "- `ts`: a 1-D numerical array which is a suitable input for `func`. Think of this as time-series data that we want to fit some model defined by `func`.\n",
    "- `grid`: a list of dictionaries. Each dictionary maps the remaining parameters for `func` to values. You can assume that the keys in these dictionaries match the remaining named parameters for `func`.  \n",
    "- `n_back`: a positive integer smaller than `ts.shape[0]`.\n",
    "\n",
    "Your function should iteratively search the parameter sets given in `grid` to determine the set which results in the best model (the one with the lowest `mse`) given `func` and `ts`. Since exponential smoothing takes time to ramp up, you should only consider the last `n_back` **observations** in `mse` calculations. If there are multiple parameter sets which result in the same `mse` the parameter set encountered _first_ in `grid` should be chosen.\n",
    "\n",
    "You can follow this whiteboard-level algorithm to implement your search.  \n",
    "1. Initialize a variable to track the lowest `mse` returned so far in the search.\n",
    "2. Initialize a variable to track the best set of parameters tested so far. \n",
    "3. Iterate through each `dict` (we will call the dict `params`) in `grid`.\n",
    "    - Calculate the predictions for this set of parameters.\n",
    "        - `func(ts, **params)` will calculate the predictions.\n",
    "    - Slice the predictions and observations so that only data points corresponding to the last `n_back` **observations** are in the slices.\n",
    "    - Calculate the `mse` of the slices.\n",
    "    - Update the tracking variables set in steps 1 and 3 if the `mse` has improved.\n",
    "4. Once all `dict`s in `grid` have been checked, return the best set of parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0c3e1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_data"
    ]
   },
   "outputs": [],
   "source": [
    "### Define demo inputs\n",
    "def demo_func_ex8(ts, a, b):\n",
    "    return np.concatenate(( np.array([np.nan]), \n",
    "                            ((5*a)/(7*b))*ts[1:], \n",
    "                            np.array([50.])))\n",
    "demo_ts_ex8 = np.array([51.1, 61.7, 34.92, 7.97, 84.03, 29.65, 85.86, 95.4, 82., 36.61])\n",
    "demo_grid_ex8 = [   {'a': 2, 'b': 5},\n",
    "                    {'a': 2, 'b': 11},\n",
    "                    {'a': 3, 'b': 5},\n",
    "                    {'a': 3, 'b': 11},\n",
    "                    {'a': 21, 'b': 15},\n",
    "                    {'a': 7, 'b': 11},\n",
    "                    {'a': 14, 'b': 10}]\n",
    "demo_n_back_ex8 = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e42650b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "demo_output_md"
    ]
   },
   "source": [
    "<!-- Expected demo output text block -->\n",
    "The demo included in the solution cell below should display the following output:\n",
    "```\n",
    "{'a': 21, 'b': 15}\n",
    "```\n",
    "Notice:  \n",
    "- `func` will return \"predictions\" $\\hat{x}_t = \\frac{5a}{7b}x_t$ whenever $0 < t \\le 9$.\n",
    "- Due to the `n_back` parameter we are only looking at the last 9 observations (same interval as in the above point).\n",
    "- When $a=7k$ and $b=5k$ with any number $k$, the fraction cancels and we have $\\hat{x}_t = x_t$. This will have MSE of 0.\n",
    "    - Both `{'a': 21, 'b': 15}` and `{'a': 14, 'b': 10}` match this form, so we choose `{'a': 21, 'b': 15}` which appeared first in `grid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c7499",
   "metadata": {
    "tags": [
     "exercise_solution"
    ]
   },
   "outputs": [],
   "source": [
    "### Exercise 8 solution\n",
    "def grid_search(func, ts, grid, n_back):\n",
    "    ### YOUR CODE HERE\n",
    "    \n",
    "### demo function call\n",
    "grid_search(func=demo_func_ex8, ts=demo_ts_ex8, grid=demo_grid_ex8, n_back=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643e4df",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "test_data_boilerplate"
    ]
   },
   "source": [
    "<!-- Test Cell Boilerplate -->\n",
    "The cell below will test your solution for Exercise 8. The testing variables will be available for debugging under the following names in a dictionary format.\n",
    "- `input_vars` - Input variables for your solution. \n",
    "- `original_input_vars` - Copy of input variables from prior to running your solution. These _should_ be the same as `input_vars` - otherwise the inputs were modified by your solution.\n",
    "- `returned_output_vars` - Outputs returned by your solution.\n",
    "- `true_output_vars` - The expected output. This _should_ \"match\" `returned_output_vars` based on the question requirements - otherwise, your solution is not returning the correct output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06573f3c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "ex8",
     "locked": true,
     "points": "3",
     "solution": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### test_cell_ex8\n",
    "from tester_fw.testers import Tester\n",
    "\n",
    "conf = {\n",
    "    'case_file':'tc_8', \n",
    "    'func': grid_search, # replace this with the function defined above\n",
    "    'inputs':{ # input config dict. keys are parameter names\n",
    "        'func':{\n",
    "            'dtype':'function', # data type of param.\n",
    "            'check_modified':False,\n",
    "        },\n",
    "        'ts':{\n",
    "            'dtype':'np.ndarray', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'grid':{\n",
    "            'dtype':'dict', # data type of param.\n",
    "            'check_modified':True,\n",
    "        },\n",
    "        'n_back':{\n",
    "            'dtype':'int', # data type of param.\n",
    "            'check_modified':False,\n",
    "        }\n",
    "    },\n",
    "    'outputs':{\n",
    "        'output_0':{\n",
    "            'index':0,\n",
    "            'dtype':'dict',\n",
    "            'check_dtype': True,\n",
    "            'check_col_dtypes': True, # Ignored if dtype is not df\n",
    "            'check_col_order': True, # Ignored if dtype is not df\n",
    "            'check_row_order': True, # Ignored if dtype is not df\n",
    "            'check_column_type': True, # Ignored if dtype is not df\n",
    "            'float_tolerance': 10 ** (-6)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "tester = Tester(conf, key=b'z0BNF11iKYQicR63590bVXZGa19YGvJcmzrbP6R7oAY=', path='')\n",
    "for _ in range(70):\n",
    "    try:\n",
    "        tester.run_test()\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "    except:\n",
    "        (input_vars, original_input_vars, returned_output_vars, true_output_vars) = tester.get_test_vars()\n",
    "        raise\n",
    "\n",
    "print('Passed! Please submit.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fba78b3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    },
    "tags": [
     "fin"
    ]
   },
   "source": [
    "**Fin.** If you have made it this far, congratulations on completing the exam. **Don't forget to submit!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
